# full-text-tokenizer
Splits a text into individual words (tokens) and reduces the amount of remaining tokens by removing unnecessary tokens and stemming and then deduplicating the remaining tokens.

## Result
The tokenizer shrinks the number of tokens by about 45%.